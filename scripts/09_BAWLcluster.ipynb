{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Shifts in Harry Potter Fanfics\n",
    "\n",
    "# BAWL Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last updated: 19.01.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Import/Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import cycle\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AffinityPropagation as AF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load KeyesVectors Harry Potter books/fanfiction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = r'Z:\\Fanfiction\\HP_Character-Distribution\\pamphlet_character_shifts\\data'\n",
    "path_models = r'Z:\\Fanfiction\\HP_Character-Distribution\\pamphlet_character_shifts\\results\\vector_models'\n",
    "path_pickled = r'Z:\\Fanfiction\\HP_Character-Distribution\\pamphlet_character_shifts\\results\\pickled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_books = KeyedVectors.load(path_models + '\\\\modelHPoriginalsD_vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ff = KeyedVectors.load(path_models + '\\\\modelHPFFsD_vectors.kv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. BAWL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load BAWL with word frequency of at least 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bawl = pd.read_csv(path_data + '\\\\bawl\\\\BAWLR_with_freqs.csv')\n",
    "bawl_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"FFS_FREQ\"] >= 50)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Originals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1a High Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for valence words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_words_index = [model_books.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [model_books.get_vector(i) for i in valence_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['lust', 'geschenk', 'spaß', 'wahrheit', 'sommer', 'ferien'], 3: ['begeistern', 'mutig', 'ehrlich', 'lieb', 'freuen', 'vertrauen', 'gefühl', 'leben', 'freund', 'lieben'], 1: ['strahlen', 'luft', 'warm', 'himmel', 'sonne'], 2: ['lächeln', 'glück', 'lachen', 'freude']}\n"
     ]
    }
   ],
   "source": [
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['lust', 'geschenk', 'spaß', 'wahrheit', 'sommer', 'ferien']\n",
      "a: AVG SIMILARITY 0.3094934562842051\n",
      "a: MEAN VALENCE 2.3872549019607843\n",
      "a: MEAN VALENCE STD 0.7148446459074046\n",
      "a: MEAN AROUSAL 3.0387570232771473\n",
      "a: MEAN AROUSAL STD 1.2357668381043003\n",
      "a: SUGGESTION VALUE 2.6559405250421024\n",
      "b: ITEMS ['strahlen', 'luft', 'warm', 'himmel', 'sonne']\n",
      "b: AVG SIMILARITY 0.32349845841526986\n",
      "b: MEAN VALENCE 2.29\n",
      "b: MEAN VALENCE STD 0.7015038295493231\n",
      "b: MEAN AROUSAL 2.296666666666667\n",
      "b: MEAN AROUSAL STD 1.0229279794503074\n",
      "b: SUGGESTION VALUE 2.440243492420639\n",
      "c: ITEMS ['lächeln', 'glück', 'lachen', 'freude']\n",
      "c: AVG SIMILARITY 0.24586826066176096\n",
      "c: MEAN VALENCE 2.5647058823529414\n",
      "c: MEAN VALENCE STD 0.6449365630774454\n",
      "c: MEAN AROUSAL 2.883893557422969\n",
      "c: MEAN AROUSAL STD 1.3073861853835012\n",
      "c: SUGGESTION VALUE 2.6323460136486108\n",
      "d: ITEMS ['begeistern', 'mutig', 'ehrlich', 'lieb', 'freuen', 'vertrauen', 'gefühl', 'leben', 'freund', 'lieben']\n",
      "d: AVG SIMILARITY 0.26679692086246276\n",
      "d: MEAN VALENCE 2.301176470588236\n",
      "d: MEAN VALENCE STD 0.7462287640487153\n",
      "d: MEAN AROUSAL 2.9224101921470345\n",
      "d: MEAN AROUSAL STD 1.2193737996285936\n",
      "d: SUGGESTION VALUE 2.9674300349357643\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_books.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['begeistern', 'mutig', 'ehrlich', 'lieb', 'freuen', 'vertrauen', 'gefühl', 'leben', 'freund', 'lieben']\n",
      "2 ['lust', 'geschenk', 'spaß', 'wahrheit', 'sommer', 'ferien']\n",
      "3 ['lächeln', 'glück', 'lachen', 'freude']\n",
      "4 ['strahlen', 'luft', 'warm', 'himmel', 'sonne']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_val_originals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_originals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_originals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1b Low Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for valence words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_words_index = [model_books.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [model_books.get_vector(i) for i in valence_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['tod', 'töten', 'zerstören', 'stehlen', 'fluch', 'zwingen', 'verletzen', 'gefahr'], 4: ['angst', 'schlecht', 'ärger', 'schlimm', 'übel', 'problem'], 1: ['tot', 'leiche', 'grab', 'kerker', 'verboten', 'werwolf'], 2: ['traurig', 'entsetzt', 'schuld'], 3: ['schlagen', 'heulen']}\n"
     ]
    }
   ],
   "source": [
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['tod', 'töten', 'zerstören', 'stehlen', 'fluch', 'zwingen', 'verletzen', 'gefahr']\n",
      "a: AVG SIMILARITY 0.2750306650996208\n",
      "a: MEAN VALENCE -2.2705882352941176\n",
      "a: MEAN VALENCE STD 0.7390226761105867\n",
      "a: MEAN AROUSAL 3.990773809523809\n",
      "a: MEAN AROUSAL STD 1.032955568604849\n",
      "a: SUGGESTION VALUE 2.6691654262959097\n",
      "b: ITEMS ['tot', 'leiche', 'grab', 'kerker', 'verboten', 'werwolf']\n",
      "b: AVG SIMILARITY 0.2563492305576801\n",
      "b: MEAN VALENCE -2.0916666666666663\n",
      "b: MEAN VALENCE STD 0.7646569141161882\n",
      "b: MEAN AROUSAL 3.903983815748522\n",
      "b: MEAN AROUSAL STD 0.9854678577212209\n",
      "b: SUGGESTION VALUE 2.121852470807677\n",
      "c: ITEMS ['traurig', 'entsetzt', 'schuld']\n",
      "c: AVG SIMILARITY 0.28608205914497375\n",
      "c: MEAN VALENCE -1.866666666666667\n",
      "c: MEAN VALENCE STD 0.6643486305132159\n",
      "c: MEAN AROUSAL 3.320105820105821\n",
      "c: MEAN AROUSAL STD 0.9038619394601151\n",
      "c: SUGGESTION VALUE 1.7230091603198396\n",
      "d: ITEMS ['schlagen', 'heulen']\n",
      "d: AVG SIMILARITY 0.37247055768966675\n",
      "d: MEAN VALENCE -1.8058823529411765\n",
      "d: MEAN VALENCE STD 0.9079906147774445\n",
      "d: MEAN AROUSAL 3.897222222222222\n",
      "d: MEAN AROUSAL STD 0.981013463668629\n",
      "d: SUGGESTION VALUE 1.400574431178372\n",
      "e: ITEMS ['angst', 'schlecht', 'ärger', 'schlimm', 'übel', 'problem']\n",
      "e: AVG SIMILARITY 0.29623184303442635\n",
      "e: MEAN VALENCE -2.037254901960784\n",
      "e: MEAN VALENCE STD 0.755239560352384\n",
      "e: MEAN AROUSAL 3.767195767195767\n",
      "e: MEAN AROUSAL STD 0.8167327769837985\n",
      "e: SUGGESTION VALUE 2.115002171968532\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_books.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['tod', 'töten', 'zerstören', 'stehlen', 'fluch', 'zwingen', 'verletzen', 'gefahr']\n",
      "2 ['tot', 'leiche', 'grab', 'kerker', 'verboten', 'werwolf']\n",
      "3 ['angst', 'schlecht', 'ärger', 'schlimm', 'übel', 'problem']\n",
      "4 ['traurig', 'entsetzt', 'schuld']\n",
      "5 ['schlagen', 'heulen']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_val_originals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_originals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_originals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2a High Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for arousal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_words_index = [model_books.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [model_books.get_vector(i) for i in arousal_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['verfolgen', 'leiden', 'gefahr'], 5: ['feuer', 'weinen', 'schlagen', 'zorn', 'schmerz', 'schreck', 'schrei', 'panik'], 2: ['schlecht', 'ärger', 'angst'], 0: ['reizen', 'drängen', 'scharf'], 3: ['zwingen', 'verraten', 'warnen', 'leid'], 4: ['kampf', 'kerker', 'leiche', 'tot']}\n"
     ]
    }
   ],
   "source": [
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['reizen', 'drängen', 'scharf']\n",
      "a: AVG SIMILARITY 0.21568880478541055\n",
      "a: MEAN VALENCE -0.5745098039215687\n",
      "a: MEAN VALENCE STD 1.1022207662885075\n",
      "a: MEAN AROUSAL 3.9461988304093567\n",
      "a: MEAN AROUSAL STD 0.8524465232931827\n",
      "a: SUGGESTION VALUE 3.831091767165072\n",
      "b: ITEMS ['verfolgen', 'leiden', 'gefahr']\n",
      "b: AVG SIMILARITY 0.2641720771789551\n",
      "b: MEAN VALENCE -1.8254901960784313\n",
      "b: MEAN VALENCE STD 1.0265575454742872\n",
      "b: MEAN AROUSAL 3.9714285714285715\n",
      "b: MEAN AROUSAL STD 0.7901114534485343\n",
      "b: SUGGESTION VALUE 3.988584429545929\n",
      "c: ITEMS ['schlecht', 'ärger', 'angst']\n",
      "c: AVG SIMILARITY 0.3494122177362442\n",
      "c: MEAN VALENCE -2.266666666666666\n",
      "c: MEAN VALENCE STD 0.6464019662600337\n",
      "c: MEAN AROUSAL 4.034391534391535\n",
      "c: MEAN AROUSAL STD 0.8017971118115712\n",
      "c: SUGGESTION VALUE 4.14662043699605\n",
      "d: ITEMS ['zwingen', 'verraten', 'warnen', 'leid']\n",
      "d: AVG SIMILARITY 0.32215701043605804\n",
      "d: MEAN VALENCE -1.4838235294117648\n",
      "d: MEAN VALENCE STD 1.1907052659492896\n",
      "d: MEAN AROUSAL 3.9722222222222223\n",
      "d: MEAN AROUSAL STD 0.8176174879351691\n",
      "d: SUGGESTION VALUE 4.226025630471847\n",
      "e: ITEMS ['kampf', 'kerker', 'leiche', 'tot']\n",
      "e: AVG SIMILARITY 0.23721246110896269\n",
      "e: MEAN VALENCE -2.1125\n",
      "e: MEAN VALENCE STD 1.0269853711742822\n",
      "e: MEAN AROUSAL 4.1039915966386555\n",
      "e: MEAN AROUSAL STD 0.8708676055910987\n",
      "e: SUGGESTION VALUE 4.218215647199076\n",
      "f: ITEMS ['feuer', 'weinen', 'schlagen', 'zorn', 'schmerz', 'schreck', 'schrei', 'panik']\n",
      "f: AVG SIMILARITY 0.3147728530956166\n",
      "f: MEAN VALENCE -1.4099264705882353\n",
      "f: MEAN VALENCE STD 1.2706866106658437\n",
      "f: MEAN AROUSAL 4.1119281045751634\n",
      "f: MEAN AROUSAL STD 0.8067919101625997\n",
      "f: SUGGESTION VALUE 5.348254328262244\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_books.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['feuer', 'weinen', 'schlagen', 'zorn', 'schmerz', 'schreck', 'schrei', 'panik']\n",
      "2 ['zwingen', 'verraten', 'warnen', 'leid']\n",
      "3 ['kampf', 'kerker', 'leiche', 'tot']\n",
      "4 ['schlecht', 'ärger', 'angst']\n",
      "5 ['verfolgen', 'leiden', 'gefahr']\n",
      "6 ['reizen', 'drängen', 'scharf']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_arousal_originals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_originals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_originals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2b Low Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"ORIGINALS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for arousal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_words_index = [model_books.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [model_books.get_vector(i) for i in arousal_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['schlaf', 'still', 'pause', 'wenig', 'schweigen'], 1: ['schale', 'kamin', 'baum', 'stumm', 'boden', 'ding', 'gras', 'teller', 'kissen', 'feder', 'becher', 'glas', 'tisch', 'hand', 'sessel'], 2: ['decke', 'himmel', 'zimmer'], 3: ['bleiben'], 4: ['reichen']}\n"
     ]
    }
   ],
   "source": [
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['schlaf', 'still', 'pause', 'wenig', 'schweigen']\n",
      "a: AVG SIMILARITY 0.29559065103530885\n",
      "a: MEAN VALENCE 0.4970588235294118\n",
      "a: MEAN VALENCE STD 1.1616949083788004\n",
      "a: MEAN AROUSAL 1.4018045112781956\n",
      "a: MEAN AROUSAL STD 0.6254920175095593\n",
      "a: SUGGESTION VALUE 2.8949819665516756\n",
      "b: ITEMS ['schale', 'kamin', 'baum', 'stumm', 'boden', 'ding', 'gras', 'teller', 'kissen', 'feder', 'becher', 'glas', 'tisch', 'hand', 'sessel']\n",
      "b: AVG SIMILARITY 0.3271927245670841\n",
      "b: MEAN VALENCE 0.7684313725490195\n",
      "b: MEAN VALENCE STD 0.9616918156166732\n",
      "b: MEAN AROUSAL 1.6276451914098973\n",
      "b: MEAN AROUSAL STD 0.7980606789191464\n",
      "b: SUGGESTION VALUE 3.953054604055741\n",
      "c: ITEMS ['decke', 'himmel', 'zimmer']\n",
      "c: AVG SIMILARITY 0.34883734583854675\n",
      "c: MEAN VALENCE 1.5533333333333335\n",
      "c: MEAN VALENCE STD 1.07971627\n",
      "c: MEAN AROUSAL 1.6355555555555557\n",
      "c: MEAN AROUSAL STD 0.8683506410051516\n",
      "c: SUGGESTION VALUE 2.1357384216827593\n",
      "d: ITEMS ['bleiben']\n",
      "d: MEAN VALENCE 0.8235294117647058\n",
      "d: MEAN VALENCE STD 0.7966059911708803\n",
      "d: MEAN AROUSAL 1.7894736842105263\n",
      "d: MEAN AROUSAL STD 0.9176629354822472\n",
      "d: SUGGESTION VALUE 0\n",
      "e: ITEMS ['reichen']\n",
      "e: MEAN VALENCE 0.6176470588235294\n",
      "e: MEAN VALENCE STD 0.985184366143778\n",
      "e: MEAN AROUSAL 1.7894736842105263\n",
      "e: MEAN AROUSAL STD 0.8549819600709617\n",
      "e: SUGGESTION VALUE 0\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_books.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['schale', 'kamin', 'baum', 'stumm', 'boden', 'ding', 'gras', 'teller', 'kissen', 'feder', 'becher', 'glas', 'tisch', 'hand', 'sessel']\n",
      "2 ['schlaf', 'still', 'pause', 'wenig', 'schweigen']\n",
      "3 ['decke', 'himmel', 'zimmer']\n",
      "4 ['bleiben']\n",
      "5 ['reichen']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_arousal_originals = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_originals.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_originals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fanfiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1a High Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_mean = 2\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] >= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "high_valence_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[-top_n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for valence words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_words_index = [model_ff.key_to_index[word] for word in high_valence_words]\n",
    "valence_word_vectors = [model_ff.get_vector(i) for i in valence_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: ['urlaub', 'zuhause', 'wahrheit', 'sommer', 'ferien'], 2: ['harmonie', 'frieden', 'freiheit'], 0: ['super', 'kreativ', 'prima', 'lieben'], 1: ['idylle', 'sonne', 'paradies'], 6: ['lebendig', 'heilung', 'gesund'], 5: ['erdbeere', 'freund', 'sex', 'küssen'], 4: ['glück', 'lachen', 'freude']}\n"
     ]
    }
   ],
   "source": [
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = high_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "\n",
    "print(valence_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['super', 'kreativ', 'prima', 'lieben']\n",
      "a: AVG SIMILARITY 0.2902863969405492\n",
      "a: MEAN VALENCE 2.626470588235294\n",
      "a: MEAN VALENCE STD 0.558484207998896\n",
      "a: MEAN AROUSAL 3.135014619883041\n",
      "a: MEAN AROUSAL STD 1.2333064966616738\n",
      "a: SUGGESTION VALUE 2.8664952998634377\n",
      "b: ITEMS ['idylle', 'sonne', 'paradies']\n",
      "b: AVG SIMILARITY 0.2452204575141271\n",
      "b: MEAN VALENCE 2.6333333333333333\n",
      "b: MEAN VALENCE STD 0.5756622808474438\n",
      "b: MEAN AROUSAL 2.335511982570806\n",
      "b: MEAN AROUSAL STD 1.3021731903900922\n",
      "b: SUGGESTION VALUE 2.6658847842637696\n",
      "c: ITEMS ['harmonie', 'frieden', 'freiheit']\n",
      "c: AVG SIMILARITY 0.3926520049571991\n",
      "c: MEAN VALENCE 2.6098039215686275\n",
      "c: MEAN VALENCE STD 0.6117400275613434\n",
      "c: MEAN AROUSAL 2.4586056644880174\n",
      "c: MEAN AROUSAL STD 1.0706733238363053\n",
      "c: SUGGESTION VALUE 2.7675524925387602\n",
      "d: ITEMS ['urlaub', 'zuhause', 'wahrheit', 'sommer', 'ferien']\n",
      "d: AVG SIMILARITY 0.35850543677806856\n",
      "d: MEAN VALENCE 2.51\n",
      "d: MEAN VALENCE STD 0.6544012272559334\n",
      "d: MEAN AROUSAL 2.3922385620915034\n",
      "d: MEAN AROUSAL STD 1.2002013055192284\n",
      "d: SUGGESTION VALUE 2.8258203800667383\n",
      "e: ITEMS ['glück', 'lachen', 'freude']\n",
      "e: AVG SIMILARITY 0.2844628592332204\n",
      "e: MEAN VALENCE 2.6549019607843136\n",
      "e: MEAN VALENCE STD 0.5694448626523393\n",
      "e: MEAN AROUSAL 3.0594771241830063\n",
      "e: MEAN AROUSAL STD 1.3352934562317997\n",
      "e: SUGGESTION VALUE 2.743478590644884\n",
      "f: ITEMS ['erdbeere', 'freund', 'sex', 'küssen']\n",
      "f: AVG SIMILARITY 0.2379167495916287\n",
      "f: MEAN VALENCE 2.5691176470588233\n",
      "f: MEAN VALENCE STD 0.6606783380718455\n",
      "f: MEAN AROUSAL 3.096134085213033\n",
      "f: MEAN AROUSAL STD 1.224118335101556\n",
      "f: SUGGESTION VALUE 2.6089092039276625\n",
      "g: ITEMS ['lebendig', 'heilung', 'gesund']\n",
      "g: AVG SIMILARITY 0.24493323266506195\n",
      "g: MEAN VALENCE 2.6\n",
      "g: MEAN VALENCE STD 0.6154659264981074\n",
      "g: MEAN AROUSAL 2.346691893131522\n",
      "g: MEAN AROUSAL STD 1.0475733962881169\n",
      "g: SUGGESTION VALUE 2.580887090301521\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_valence_words)[class_members])))\n",
    "    for member1 in np.array(high_valence_words)[class_members]:\n",
    "        for member2 in np.array(high_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_ff.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['super', 'kreativ', 'prima', 'lieben']\n",
      "2 ['urlaub', 'zuhause', 'wahrheit', 'sommer', 'ferien']\n",
      "3 ['harmonie', 'frieden', 'freiheit']\n",
      "4 ['glück', 'lachen', 'freude']\n",
      "5 ['idylle', 'sonne', 'paradies']\n",
      "6 ['erdbeere', 'freund', 'sex', 'küssen']\n",
      "7 ['lebendig', 'heilung', 'gesund']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_val_ffs = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_val_ffs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_val_ffs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1b Low Valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_mean = -2\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"EMO_MEAN\"] <= emo_mean) & (bawl[\"EMO_STD\"] <= emo_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant valence words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_n = 25\n",
    "emo_std = 1\n",
    "\n",
    "low_valence_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"EMO_STD\"] <= emo_std)].sort_values(\"EMO_MEAN\")[\"WORD_LOWER\"])[:bot_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for valence words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_words_index = [model_ff.key_to_index[word] for word in low_valence_words]\n",
    "valence_word_vectors = [model_ff.get_vector(i) for i in valence_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_word_cosine = np.array(normalize(valence_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence_cos_cluster = AF(affinity='euclidean')\n",
    "valence_cos_cluster.fit(valence_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['krieg', 'weltkrieg', 'tod', 'alptraum'], 2: ['foltern', 'mord', 'töten', 'morden', 'lynchen', 'angst', 'zerstören', 'tot', 'gift', 'hassen', 'leiche'], 1: ['massaker', 'folter', 'gewalt', 'qual', 'strafe'], 3: ['todfeind', 'erzfeind'], 4: ['tyrann', 'unmensch', 'herzlos']}\n"
     ]
    }
   ],
   "source": [
    "valence_sem_groups = {}\n",
    "for i in range(len(valence_cos_cluster.labels_)):\n",
    "    label = valence_cos_cluster.labels_[i]\n",
    "    if label not in valence_sem_groups.keys():\n",
    "        valence_sem_groups[label] = []\n",
    "\n",
    "    word = low_valence_words[i]\n",
    "    valence_sem_groups[label].append(word)\n",
    "    \n",
    "print(valence_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['krieg', 'weltkrieg', 'tod', 'alptraum']\n",
      "a: AVG SIMILARITY 0.32669998953739804\n",
      "a: MEAN VALENCE -2.8308823529411766\n",
      "a: MEAN VALENCE STD 0.5392358281616656\n",
      "a: MEAN AROUSAL 4.443860877684407\n",
      "a: MEAN AROUSAL STD 0.8094890873299709\n",
      "a: SUGGESTION VALUE 3.182616552817918\n",
      "b: ITEMS ['massaker', 'folter', 'gewalt', 'qual', 'strafe']\n",
      "b: AVG SIMILARITY 0.3434549242258072\n",
      "b: MEAN VALENCE -2.68\n",
      "b: MEAN VALENCE STD 0.6023514378132673\n",
      "b: MEAN AROUSAL 4.309857978279031\n",
      "b: MEAN AROUSAL STD 0.7021633726519599\n",
      "b: SUGGESTION VALUE 3.090009740612795\n",
      "c: ITEMS ['foltern', 'mord', 'töten', 'morden', 'lynchen', 'angst', 'zerstören', 'tot', 'gift', 'hassen', 'leiche']\n",
      "c: AVG SIMILARITY 0.29135472567921333\n",
      "c: MEAN VALENCE -2.607754010695187\n",
      "c: MEAN VALENCE STD 0.6729715543654162\n",
      "c: MEAN AROUSAL 4.271375408217514\n",
      "c: MEAN AROUSAL STD 0.8975550393354602\n",
      "c: SUGGESTION VALUE 3.807450038956106\n",
      "d: ITEMS ['todfeind', 'erzfeind']\n",
      "d: AVG SIMILARITY 0.49981966614723206\n",
      "d: MEAN VALENCE -2.6\n",
      "d: MEAN VALENCE STD 0.6009974172026415\n",
      "d: MEAN AROUSAL 4.098039215686274\n",
      "d: MEAN AROUSAL STD 1.1014484802526745\n",
      "d: SUGGESTION VALUE 2.7549515294614113\n",
      "e: ITEMS ['tyrann', 'unmensch', 'herzlos']\n",
      "e: AVG SIMILARITY 0.4202001790205638\n",
      "e: MEAN VALENCE -2.533333333333333\n",
      "e: MEAN VALENCE STD 0.6934602746327051\n",
      "e: MEAN AROUSAL 3.337952724949629\n",
      "e: MEAN AROUSAL STD 1.2016502715415283\n",
      "e: SUGGESTION VALUE 2.616317281816995\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(valence_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = valence_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_valence_words)[class_members])))\n",
    "    for member1 in np.array(low_valence_words)[class_members]:\n",
    "        for member2 in np.array(low_valence_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_ff.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in valence_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + abs(sum(valence_means) / len(valence_means)) - (sum(valence_stds) / len(valence_stds)))*(1.05**(len(np.array(high_valence_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_valence_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['foltern', 'mord', 'töten', 'morden', 'lynchen', 'angst', 'zerstören', 'tot', 'gift', 'hassen', 'leiche']\n",
      "2 ['krieg', 'weltkrieg', 'tod', 'alptraum']\n",
      "3 ['massaker', 'folter', 'gewalt', 'qual', 'strafe']\n",
      "4 ['todfeind', 'erzfeind']\n",
      "5 ['tyrann', 'unmensch', 'herzlos']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_val_ffs = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_val_ffs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_val_ffs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2a High Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] >= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "high_arousal_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[-top_n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for arousal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_words_index = [model_ff.key_to_index[word] for word in high_arousal_words]\n",
    "arousal_word_vectors = [model_ff.get_vector(i) for i in arousal_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: ['morden', 'mord', 'brutal', 'todfeind', 'massaker', 'attentat'], 4: ['trauma', 'terror', 'unheil', 'alptraum', 'krieg', 'weltkrieg'], 5: ['furcht', 'atemnot', 'ekstase', 'bestie', 'panik'], 3: ['schrei', 'alarm', 'erdbeben', 'notfall'], 0: ['erotik'], 1: ['hassen', 'foltern', 'folter']}\n"
     ]
    }
   ],
   "source": [
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = high_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['erotik']\n",
      "a: MEAN VALENCE 2.3\n",
      "a: MEAN VALENCE STD 0.483045891539648\n",
      "a: MEAN AROUSAL 4.4375\n",
      "a: MEAN AROUSAL STD 0.8139410298049853\n",
      "a: SUGGESTION VALUE 0\n",
      "b: ITEMS ['hassen', 'foltern', 'folter']\n",
      "b: AVG SIMILARITY 0.3543806274731954\n",
      "b: MEAN VALENCE -2.6999999999999997\n",
      "b: MEAN VALENCE STD 0.5510494533333333\n",
      "b: MEAN AROUSAL 4.524366471734893\n",
      "b: MEAN AROUSAL STD 0.7406004551268303\n",
      "b: SUGGESTION VALUE 4.790422008854566\n",
      "c: ITEMS ['morden', 'mord', 'brutal', 'todfeind', 'massaker', 'attentat']\n",
      "c: AVG SIMILARITY 0.3539106547832489\n",
      "c: MEAN VALENCE -2.566666666666667\n",
      "c: MEAN VALENCE STD 0.5612380832003703\n",
      "c: MEAN AROUSAL 4.534342391927531\n",
      "c: MEAN AROUSAL STD 0.803956688095666\n",
      "c: SUGGESTION VALUE 5.473347745200678\n",
      "d: ITEMS ['schrei', 'alarm', 'erdbeben', 'notfall']\n",
      "d: AVG SIMILARITY 0.2482155834635099\n",
      "d: MEAN VALENCE -1.6\n",
      "d: MEAN VALENCE STD 0.8489156716345836\n",
      "d: MEAN AROUSAL 4.466374269005848\n",
      "d: MEAN AROUSAL STD 0.7250215146529922\n",
      "d: SUGGESTION VALUE 4.849345249417905\n",
      "e: ITEMS ['trauma', 'terror', 'unheil', 'alptraum', 'krieg', 'weltkrieg']\n",
      "e: AVG SIMILARITY 0.270525798201561\n",
      "e: MEAN VALENCE -2.4955882352941177\n",
      "e: MEAN VALENCE STD 0.6818016467688311\n",
      "e: MEAN AROUSAL 4.530812324929972\n",
      "e: MEAN AROUSAL STD 0.6876221081460301\n",
      "e: SUGGESTION VALUE 5.512772898451321\n",
      "f: ITEMS ['furcht', 'atemnot', 'ekstase', 'bestie', 'panik']\n",
      "f: AVG SIMILARITY 0.31554483696818353\n",
      "f: MEAN VALENCE -1.26\n",
      "f: MEAN VALENCE STD 0.9079483308895832\n",
      "f: MEAN AROUSAL 4.493382352941176\n",
      "f: MEAN AROUSAL STD 0.7606823490733079\n",
      "f: SUGGESTION VALUE 5.1667002508448014\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(high_arousal_words)[class_members])))\n",
    "    for member1 in np.array(high_arousal_words)[class_members]:\n",
    "        for member2 in np.array(high_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_ff.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + sum(arousal_means) / len(arousal_means) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(high_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(high_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['trauma', 'terror', 'unheil', 'alptraum', 'krieg', 'weltkrieg']\n",
      "2 ['morden', 'mord', 'brutal', 'todfeind', 'massaker', 'attentat']\n",
      "3 ['furcht', 'atemnot', 'ekstase', 'bestie', 'panik']\n",
      "4 ['schrei', 'alarm', 'erdbeben', 'notfall']\n",
      "5 ['hassen', 'foltern', 'folter']\n",
      "6 ['erotik']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_arousal_ffs = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\high_arousal_ffs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(high_arousal_ffs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2b Low Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_mean = 2\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"AROUSAL_MEAN\"] <= arousal_mean) & (bawl[\"AROUSAL_STD\"] <= arousal_std)][\"WORD_LOWER\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relevant arousal words by ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_n = 25\n",
    "arousal_std = 1\n",
    "\n",
    "low_arousal_words = list(bawl[(bawl[\"FFS_FREQ\"] >= 50) & (bawl[\"AROUSAL_STD\"] <= arousal_std)].sort_values(\"AROUSAL_MEAN\")[\"WORD_LOWER\"])[:bot_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors for arousal words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_words_index = [model_ff.key_to_index[word] for word in low_arousal_words]\n",
    "arousal_word_vectors = [model_ff.get_vector(i) for i in arousal_words_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize vectors on unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_word_cosine = np.array(normalize(arousal_word_vectors,norm='l2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brottrager\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_affinity_propagation.py:148: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 1.0 (renaming of 0.25) which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AffinityPropagation()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal_cos_cluster = AF(affinity='euclidean')\n",
    "arousal_cos_cluster.fit(arousal_word_cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform cluster to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['schlaf', 'erholung', 'balsam', 'friede'], 2: ['still', 'pause', 'wenig'], 5: ['wiege', 'murmel', 'harfe'], 3: ['allee', 'buche', 'wiese', 'birke', 'linde', 'baum'], 4: ['aquarium', 'beutel', 'schale', 'kamin'], 1: ['weich', 'seide', 'zaghaft'], 6: ['zahm', 'passiv']}\n"
     ]
    }
   ],
   "source": [
    "arousal_sem_groups = {}\n",
    "for i in range(len(arousal_cos_cluster.labels_)):\n",
    "    label = arousal_cos_cluster.labels_[i]\n",
    "    if label not in arousal_sem_groups.keys():\n",
    "        arousal_sem_groups[label] = []\n",
    "\n",
    "    word = low_arousal_words[i]\n",
    "    arousal_sem_groups[label].append(word)\n",
    "    \n",
    "print(arousal_sem_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print relevant information of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: ITEMS ['schlaf', 'erholung', 'balsam', 'friede']\n",
      "a: AVG SIMILARITY 0.26079168791572255\n",
      "a: MEAN VALENCE 1.9749999999999996\n",
      "a: MEAN VALENCE STD 0.8620923284305765\n",
      "a: MEAN AROUSAL 1.2787925696594429\n",
      "a: MEAN AROUSAL STD 0.6286330724775046\n",
      "a: SUGGESTION VALUE 2.8605311371818876\n",
      "b: ITEMS ['weich', 'seide', 'zaghaft']\n",
      "b: AVG SIMILARITY 0.2685020789504051\n",
      "b: MEAN VALENCE 0.6833333333333332\n",
      "b: MEAN VALENCE STD 0.6742425666666666\n",
      "b: MEAN AROUSAL 1.4375644994840042\n",
      "b: MEAN AROUSAL STD 0.7186285995138822\n",
      "b: SUGGESTION VALUE 2.4452616829175344\n",
      "c: ITEMS ['still', 'pause', 'wenig']\n",
      "c: AVG SIMILARITY 0.2568315714597702\n",
      "c: MEAN VALENCE 0.2833333333333333\n",
      "c: MEAN VALENCE STD 0.9889026933333334\n",
      "c: MEAN AROUSAL 1.390142021720969\n",
      "c: MEAN AROUSAL STD 0.6106310947327894\n",
      "c: SUGGESTION VALUE 2.611669668976335\n",
      "d: ITEMS ['allee', 'buche', 'wiese', 'birke', 'linde', 'baum']\n",
      "d: AVG SIMILARITY 0.39870959222316743\n",
      "d: MEAN VALENCE 1.325\n",
      "d: MEAN VALENCE STD 1.056007904946277\n",
      "d: MEAN AROUSAL 1.4131693613117762\n",
      "d: MEAN AROUSAL STD 0.6059409624777441\n",
      "d: SUGGESTION VALUE 3.188890606062371\n",
      "e: ITEMS ['aquarium', 'beutel', 'schale', 'kamin']\n",
      "e: AVG SIMILARITY 0.3323992465933164\n",
      "e: MEAN VALENCE 0.8724999999999999\n",
      "e: MEAN VALENCE STD 0.9547382575\n",
      "e: MEAN AROUSAL 1.4386842105263158\n",
      "e: MEAN AROUSAL STD 0.6679402391054482\n",
      "e: SUGGESTION VALUE 2.705443176799249\n",
      "f: ITEMS ['wiege', 'murmel', 'harfe']\n",
      "f: AVG SIMILARITY 0.25707611441612244\n",
      "f: MEAN VALENCE 1.2666666666666666\n",
      "f: MEAN VALENCE STD 1.0050671\n",
      "f: MEAN AROUSAL 1.4171539961013646\n",
      "f: MEAN AROUSAL STD 0.5782545617525786\n",
      "f: SUGGESTION VALUE 2.618162905165293\n",
      "g: ITEMS ['zahm', 'passiv']\n",
      "g: AVG SIMILARITY 0.3293936848640442\n",
      "g: MEAN VALENCE -0.30000000000000004\n",
      "g: MEAN VALENCE STD 0.7050000000000001\n",
      "g: MEAN AROUSAL 1.4473684210526316\n",
      "g: MEAN AROUSAL STD 0.898162445036949\n",
      "g: SUGGESTION VALUE 2.187208757698846\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = []\n",
    "\n",
    "letters = cycle('abcdefghijklmnopqrstuvxyz')\n",
    "for k, let in zip(range(len(arousal_cos_cluster.cluster_centers_)), letters):\n",
    "    class_members = arousal_cos_cluster.labels_ == k\n",
    "\n",
    "    dist_list = []\n",
    "    print(let + \": ITEMS \" + str(list(np.array(low_arousal_words)[class_members])))\n",
    "    for member1 in np.array(low_arousal_words)[class_members]:\n",
    "        for member2 in np.array(low_arousal_words)[class_members]:\n",
    "            if member1 != member2:\n",
    "                dist_list.append(model_ff.similarity(member1,member2))\n",
    "    if (dist_list != []):\n",
    "        print(let + \": AVG SIMILARITY \" + str(sum(dist_list) / len(dist_list)))\n",
    "        \n",
    "    valence_means = []\n",
    "    valence_stds = []\n",
    "    arousal_means = []\n",
    "    arousal_stds = []\n",
    "    for word in arousal_sem_groups[k]:\n",
    "        word_row = bawl[bawl[\"WORD_LOWER\"] == word]\n",
    "        valence_means.append(float(word_row[\"EMO_MEAN\"]))\n",
    "        valence_stds.append(float(word_row[\"EMO_STD\"]))\n",
    "        arousal_means.append(float(word_row[\"AROUSAL_MEAN\"]))\n",
    "        arousal_stds.append(float(word_row[\"AROUSAL_STD\"]))\n",
    "\n",
    "    print(let + \": MEAN VALENCE \" + str(sum(valence_means) / len(valence_means)))\n",
    "    print(let + \": MEAN VALENCE STD \" + str(sum(valence_stds) / len(valence_stds)))\n",
    "    print(let + \": MEAN AROUSAL \" + str(sum(arousal_means) / len(arousal_means)))\n",
    "    print(let + \": MEAN AROUSAL STD \" + str(sum(arousal_stds) / len(arousal_stds)))\n",
    "    \n",
    "    try:\n",
    "        suggestion_value = (sum(dist_list) / len(dist_list) + (4 - sum(arousal_means) / len(arousal_means)) - (sum(arousal_stds) / len(arousal_stds)))*(1.05**(len(np.array(low_arousal_words)[class_members])))\n",
    "    except:\n",
    "        suggestion_value = 0\n",
    "    suggestion_values.append((suggestion_value,np.array(low_arousal_words)[class_members]))    \n",
    "    print(let + \": SUGGESTION VALUE \" + str(suggestion_values[-1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking for suggestion values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['allee', 'buche', 'wiese', 'birke', 'linde', 'baum']\n",
      "2 ['schlaf', 'erholung', 'balsam', 'friede']\n",
      "3 ['aquarium', 'beutel', 'schale', 'kamin']\n",
      "4 ['wiege', 'murmel', 'harfe']\n",
      "5 ['still', 'pause', 'wenig']\n",
      "6 ['weich', 'seide', 'zaghaft']\n",
      "7 ['zahm', 'passiv']\n"
     ]
    }
   ],
   "source": [
    "suggestion_values = sorted(suggestion_values, key=lambda tup: tup[0], reverse=True)\n",
    "for rank in range(len(suggestion_values)):\n",
    "    print(str(rank+1) + \" \" + str(list(suggestion_values[rank][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_arousal_ffs = list(suggestion_values[0][1])\n",
    "with open(path_pickled + \"\\\\low_arousal_ffs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(low_arousal_ffs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
